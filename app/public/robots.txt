# robots.txt
# Block ALL search engines and crawlers
User-agent: *
Disallow: /

# Explicitly block major search engines for extra certainty
User-agent: Googlebot
Disallow: /

User-agent: Bingbot
Disallow: /

User-agent: DuckDuckBot
Disallow: /

User-agent: Slurp
Disallow: /

User-agent: Baiduspider
Disallow: /

User-agent: YandexBot
Disallow: /

# No crawl delay needed since we're blocking everything
# No sitemap needed since we're blocking everything

# This file tells all search engines not to index or crawl any page on this website